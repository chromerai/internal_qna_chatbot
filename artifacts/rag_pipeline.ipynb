{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcfb252b",
   "metadata": {},
   "source": [
    "```\n",
    "Conflicting Policy RAG System\n",
    "A RAG pipeline that handles temporal conflicts, noise filtering, and source attribution.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663c58fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/k_chromerai/miniforge3/envs/policy-rag/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "\n",
    "from google import genai\n",
    "from langchain_core.documents import Document\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756cfaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PYDANTIC MODELS FOR TYPE SAFETY\n",
    "\n",
    "class DocType(str, Enum):\n",
    "    \"Document Type Enumeration\"\n",
    "    POLICY = \"policy\"\n",
    "    MENU = 'menu'\n",
    "    MEMO = 'memo'\n",
    "    GENERAL = 'general'\n",
    "\n",
    "class PolicyMetaData(BaseModel):\n",
    "    \"Type-safe Meta Data for Documents\"\n",
    "    source: str = Field(description=\"FileName of the document\")\n",
    "    doc_type: DocType = Field(description=\"Type of document: policy, menu, memo, general\")\n",
    "    effective_date: str = Field(description=\"ISO format date (YYYY-MM-dd) when the policy became effective\")\n",
    "    version: int = Field(default = 0, description=\"Version of the document if available otherwise 1\")\n",
    "    year: int = Field(description=\"Year extracted from effective-date\")\n",
    "\n",
    "    @field_validator('effective_date', mode='after')\n",
    "    @classmethod\n",
    "    def validate_date(cls, value: str) -> str:\n",
    "        \"\"\"Validate ISO FORMAT date\"\"\"\n",
    "        try:\n",
    "            datetime.fromisoformat(value)\n",
    "            return value\n",
    "        except ValueError:\n",
    "            raise ValueError(f\"Must be ISO format date (YYYY-MM-DD), got: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "409f21af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyAnswer(BaseModel):\n",
    "    \"\"\"\n",
    "    Structured LLM output with enforced citations\n",
    "    \"\"\"\n",
    "\n",
    "    answer: str = Field(description=\"Direct answer to the employee's question\")\n",
    "    reasoning: str = Field(description=\"Brief explanation for choosing this answer\")\n",
    "    cited_sources: List[str] | None = Field(description=\"Exact filenames of documents used as sources\")\n",
    "    policy_allows_remote: bool | None = Field(\n",
    "        description=\"Whether the current policy allows remote work (true/false/null if not applicable)\"\n",
    "    )\n",
    "\n",
    "class QueryIntent(BaseModel):\n",
    "    \"\"\"\n",
    "        Structured LLM output for classifying query intent for better query understanding\n",
    "    \"\"\"\n",
    "\n",
    "    intent: DocType = Field(\"Type of query: policy, menu, memo, general\")\n",
    "    reasoning: str = Field(\"Brief reasoning for the query classification ( 1 line )\")\n",
    "    confidence: int = Field(\"Confidence score between 1 and 5\", ge=1, le=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e82b0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METADATA EXTRACTOR\n",
    "class DocumentMetadata:\n",
    "    \"\"\"\n",
    "        MetaData Extraction from files\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filename, content):\n",
    "        self.filename = filename\n",
    "        self.content = content\n",
    "\n",
    "        self.docType = self._classify_doc_type()\n",
    "        self.effective_date = self._extract_date()\n",
    "        self.version = self._extract_version_info()\n",
    "\n",
    "\n",
    "    def _classify_doc_type(self) -> str:\n",
    "        \"\"\"\n",
    "            Classify document based on filename and content keywords.\n",
    "        \"\"\"\n",
    "\n",
    "        filename = self.filename.lower()\n",
    "        content = self.content.lower()\n",
    "\n",
    "        if 'policy' in filename:\n",
    "            return DocType.POLICY.value\n",
    "        elif 'menu' in filename or 'cafeteria' in filename:\n",
    "            return DocType.MENU.value\n",
    "        elif 'memo' in filename:\n",
    "            return DocType.MEMO.value\n",
    "        else:\n",
    "            return DocType.GENERAL.value\n",
    "        \n",
    "    def _extract_date(self) -> datetime:\n",
    "        #searching from filename - easier\n",
    "        year_match = re.search(r'_(\\d{4})\\.txt', self.filename)\n",
    "        if year_match:\n",
    "            year = int(year_match.group(1))\n",
    "            return datetime(year, 1, 1)\n",
    "        \n",
    "        #searching from content - more complex\n",
    "\n",
    "        date_patterns = [\n",
    "            (r'Effective Date:\\s*([A-Za-z]+\\s+\\d{1,2}, \\s+\\d{4})', \"%b %d, %Y\"),\n",
    "            (r'Effective Date:\\s*(\\d{4}-\\d{2}-\\d{2})', '%Y-%m-%d'),\n",
    "        ]\n",
    "\n",
    "        for pattern, date_format in date_patterns:\n",
    "            match = re.search(pattern, self.content)\n",
    "            if match:\n",
    "                try:\n",
    "                    date_str = match.group(1)\n",
    "                    return datetime.strptime(date_str, date_format)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        \n",
    "        file_path = Path(\"knowledge_base\", self.filename).resolve()\n",
    "        doc_date = datetime.fromtimestamp(os.path.getmtime(file_path))\n",
    "        print(f\"Warning: No date in {self.filename}, using file date: {doc_date.strftime('%Y-%m-%d')}\")\n",
    "        return  doc_date\n",
    "    \n",
    "    def _extract_version_info(self):\n",
    "        \"\"\"Extract version number (v1, v2, v3, etc.)\"\"\"\n",
    "        version_match = re.search(r'_v(\\d+)_', self.filename)\n",
    "        if version_match:\n",
    "            return int(version_match.group(1))\n",
    "        return 0\n",
    "    \n",
    "    def _to_pydantic(self) -> PolicyMetaData:\n",
    "        return PolicyMetaData(\n",
    "            source=self.filename,\n",
    "            doc_type=self.docType,\n",
    "            effective_date=self.effective_date.isoformat(),\n",
    "            version= self.version,\n",
    "            year=self.effective_date.year\n",
    "        )\n",
    "    \n",
    "    def _to_langchain_document(self) -> Document:\n",
    "        return Document(\n",
    "            page_content=self.content,\n",
    "            metadata=self._to_pydantic().model_dump()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ef612",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RagEngine:\n",
    "    \"\"\"\n",
    "        RAG engine with conflict resolution and noise filtering.\n",
    "        - LangChain vector store (for embeddings only)\n",
    "        - Pydantic validation\n",
    "        - Native Gemini API with schema support\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, knowledge_base_path: str = \"knowledge_base\"):\n",
    "        self.kb_path = Path(knowledge_base_path)\n",
    "        self.api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"GEMINI_API_KEY not found in environment\")\n",
    "        \n",
    "        print(\"Initializing RAG Pipeline...\")\n",
    "\n",
    "        self.client = genai.Client(api_key=self.api_key)\n",
    "\n",
    "        self.embedding = GoogleGenerativeAIEmbeddings(\n",
    "            model=\"gemini-embedding-001\",\n",
    "            google_api_key=self.api_key,\n",
    "            output_dimensionality=768,\n",
    "            task_type=\"retrieval-document\"\n",
    "        )\n",
    "\n",
    "        self.vectorstore = None\n",
    "    \n",
    "    def ingest_documents(self):\n",
    "        print(f\"üìö Ingesting documents from: {self.kb_path}\")\n",
    "        \n",
    "        if not self.kb_path.exists():\n",
    "            raise FileNotFoundError(f\"Knowledge base not found: {self.kb_path}\")\n",
    "        \n",
    "        txt_files = list(self.kb_path.glob(\"*.txt\"))\n",
    "        \n",
    "        if not txt_files:\n",
    "            raise FileNotFoundError(f\"No .txt files in {self.kb_path}\")\n",
    "        \n",
    "        print(f\"Found {len(txt_files)} files\\n\")\n",
    "\n",
    "        all_documents = []  # Changed from all_chunks\n",
    "        \n",
    "        for filepath in txt_files:\n",
    "            print(f\"  üìÑ Processing: {filepath.name}\")\n",
    "            \n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            metadata_extractor = DocumentMetadata(filepath.name, content)\n",
    "            langchain_doc = metadata_extractor._to_langchain_document()\n",
    "            \n",
    "            # Display extracted metadata\n",
    "            meta = metadata_extractor._to_pydantic()\n",
    "            print(f\"      Type: {meta.doc_type}\")\n",
    "            print(f\"      Date: {meta.year}\")\n",
    "            print(f\"      Version: {meta.version}\")\n",
    "            \n",
    "            # CHANGED: Add entire document as-is (no chunking!)\n",
    "            all_documents.append(langchain_doc)\n",
    "            print()\n",
    "\n",
    "        print(\"üî® Creating vector store...\")\n",
    "        self.vectorstore = Chroma.from_documents(\n",
    "            documents=all_documents,  # Changed from all_chunks\n",
    "            embedding=self.embedding,\n",
    "            collection_name=\"techcorp_docs\"  # Changed name\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Indexed {len(all_documents)} documents from {len(txt_files)} files\\n\")\n",
    "    \n",
    "    def _retrieve_documents(self, query: str, k: int = 10) -> List[Document]:\n",
    "        \"\"\"Retrieve relevant documents using vector similarity.\"\"\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"Documents not ingested. Call ingest_documents() first.\")\n",
    "        \n",
    "        # Retrieve more than needed since we'll filter\n",
    "        results = self.vectorstore.similarity_search(query, k=k)\n",
    "        print(f\"    Retrieved {len(results)} documents\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _classify_query_intent(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        Use Gemini to classify query intent and determine which doc types are needed.\n",
    "        \n",
    "        Returns:\n",
    "            One of: 'policy', 'menu', 'memo', 'general'\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"Classify this employee query into ONE category based on what type of document would answer it:\n",
    "\n",
    "- \"policy\" - Questions about rules, permissions, procedures, what's allowed/not allowed, work requirements, benefits, HR matters, remote work, time off, company guidelines\n",
    "- \"menu\" - Questions about food, cafeteria, meals, dining, lunch, dinner, breakfast\n",
    "- \"memo\" - Questions about announcements, updates, communications, notices\n",
    "- \"general\" - Unclear or could need multiple document types\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Respond with ONLY the category name (policy, menu, memo, or general). Nothing else.\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.client.models.generate_content(\n",
    "                model=\"gemini-2.5-flash\",\n",
    "                contents=prompt,\n",
    "                config={\n",
    "                        \"temperature\": 0,\n",
    "                         \"response_mime_type\": \"application/json\",\n",
    "                        \"response_json_schema\": QueryIntent.model_json_schema()\n",
    "                        }\n",
    "            )\n",
    "            \n",
    "            result = QueryIntent.model_validate_json(response.text)\n",
    "            \n",
    "            print(f\"    Query intent: {result.intent}\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    Intent classification failed: {e}, defaulting to 'general'\")\n",
    "            return 'general'\n",
    "    \n",
    "    def _filter_documents_by_metadata(self, documents: List[Document], query: str) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Filter documents based on query intent and metadata.\n",
    "        Returns only the most relevant and up-to-date documents.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Step 1: Classify query intent\n",
    "        result = self._classify_query_intent(query)\n",
    "        intent = result.intent.value\n",
    "        \n",
    "        print(f\"\\n  Intent: {intent}\")\n",
    "        print(f\"    Documents before filtering: {len(documents)}\")\n",
    "        \n",
    "        # Step 2: Filter by document type based on intent\n",
    "        if intent == 'menu':\n",
    "            filtered_docs = [d for d in documents if d.metadata.get('doc_type') == 'menu']\n",
    "            print(f\"    Keeping only MENU documents: {len(filtered_docs)}\")\n",
    "            return filtered_docs\n",
    "        \n",
    "        elif intent == 'memo':\n",
    "            filtered_docs = [d for d in documents if d.metadata.get('doc_type') == 'memo']\n",
    "            print(f\"    Keeping only MEMO documents: {len(filtered_docs)}\")\n",
    "            return filtered_docs\n",
    "        \n",
    "        elif intent == 'policy':\n",
    "            policy_docs = [d for d in documents if d.metadata.get('doc_type') == 'policy']\n",
    "            print(f\"    Found {len(policy_docs)} policy documents\")\n",
    "            return self._filter_latest_policy(policy_docs)\n",
    "        \n",
    "        else:  # general\n",
    "            print(f\"    General query - filtering all document types\")\n",
    "            return self._filter_latest_policy(documents)\n",
    "\n",
    "    def _filter_latest_policy(self, documents: List[Document]) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Keep only the latest version of policy documents.\n",
    "        Non-policy documents pass through unchanged.\n",
    "        \"\"\"\n",
    "        if not documents:\n",
    "            return []\n",
    "        \n",
    "        # Separate policies from other doc types\n",
    "        policy_docs = [d for d in documents if d.metadata.get('doc_type') == 'policy']\n",
    "        other_docs = [d for d in documents if d.metadata.get('doc_type') != 'policy']\n",
    "        \n",
    "        # If no policies or only one policy, no filtering needed\n",
    "        if len(policy_docs) <= 1:\n",
    "            return documents\n",
    "        \n",
    "        # Find the latest policy\n",
    "        print(f\"        Multiple policies detected: {len(policy_docs)}\")\n",
    "        \n",
    "        latest_policy = None\n",
    "        latest_year = 0\n",
    "        latest_version = 0\n",
    "        \n",
    "        for doc in policy_docs:\n",
    "            year = doc.metadata.get('year', 0)\n",
    "            version = doc.metadata.get('version', 0)\n",
    "            source = doc.metadata.get('source', 'unknown')\n",
    "            \n",
    "            print(f\"      - {source}: year={year}, version={version}\")\n",
    "            \n",
    "            # Compare by year first, then version\n",
    "            if (year > latest_year) or (year == latest_year and version > latest_version):\n",
    "                latest_policy = doc\n",
    "                latest_year = year\n",
    "                latest_version = version\n",
    "        \n",
    "        if latest_policy:\n",
    "            print(f\"        Keeping latest: {latest_policy.metadata.get('source')} \"\n",
    "                f\"(year: {latest_year}, v{latest_version})\")\n",
    "            return [latest_policy] + other_docs\n",
    "        \n",
    "        return documents\n",
    "    \n",
    "    def retrieve_relevant_context(self, query: str, k: int = 5) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Main retrieval method:\n",
    "        1. Retrieve top-k documents by similarity\n",
    "        2. Filter by document metadata (conflict resolution)\n",
    "        3. Return only relevant and up-to-date documents\n",
    "        \"\"\"\n",
    "        print(\" RETRIEVAL PHASE\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # Step 1: Vector similarity search\n",
    "        documents = self._retrieve_documents(query, k=k)\n",
    "        \n",
    "        # Step 2: Filter by metadata and get latest versions\n",
    "        filtered_docs = self._filter_documents_by_metadata(documents, query)\n",
    "        \n",
    "        print(f\"    Final documents: {len(filtered_docs)}\")\n",
    "        print(\"-\" * 70 + \"\\n\")\n",
    "        \n",
    "        return filtered_docs\n",
    "        \n",
    "    def _build_context(self, documents: List[Document]) -> str:\n",
    "        \"\"\"\n",
    "        Build context string from filtered documents.\n",
    "        Each document is already complete (no chunking).\n",
    "        \"\"\"\n",
    "        context_parts = []\n",
    "        \n",
    "        for doc in documents:\n",
    "            meta = doc.metadata\n",
    "            \n",
    "            context_parts.append(\n",
    "                f\"=== Document: {meta.get('source', 'unknown')} ===\\n\"\n",
    "                f\"Type: {meta.get('doc_type', 'unknown')}\\n\"\n",
    "                f\"Year: {meta.get('year', 'N/A')}\\n\"\n",
    "                f\"Version: v{meta.get('version', 'N/A')}\\n\"\n",
    "                f\"Effective Date: {meta.get('effective_date', 'N/A')}\\n\\n\"\n",
    "                f\"Content:\\n{doc.page_content}\\n\"\n",
    "            )\n",
    "        \n",
    "        return \"\\n\".join(context_parts)\n",
    "    \n",
    "    def query(self, question: str) -> str:\n",
    "        \"\"\"\n",
    "        Main query method.\n",
    "        \n",
    "        Args:\n",
    "            question: User's question\n",
    "        \n",
    "        Returns:\n",
    "            Answer from Gemini with citations\n",
    "        \"\"\"\n",
    "        print(\"=\"*70)\n",
    "        print(f\"QUERY: {question}\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "        \n",
    "        # Retrieve 5 documents initially (not 9 chunks)\n",
    "        relevant_docs = self.retrieve_relevant_context(question, k=5)\n",
    "        \n",
    "        if not relevant_docs:\n",
    "            return \"No relevant documents found to answer your question.\"\n",
    "        \n",
    "        context = self._build_context(relevant_docs)\n",
    "        \n",
    "        answer = self._generate_answer(question, context)\n",
    "\n",
    "        print(\"\\n   Generated answer\")\n",
    "        return answer\n",
    "    \n",
    "    def _generate_answer(self, question: str, context: str) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer using Gemini API.\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"You are a helpful HR assistant for TechCorp Inc.\n",
    "\n",
    "Answer the employee's question using ONLY the provided documents.\n",
    "\n",
    "1. ONLY answer if the documents contain relevant information to the question.\n",
    "2. ALWAYS prioritize the MOST RECENT policy when there are conflicts\n",
    "3. If an older policy contradicts a newer policy, the NEWER policy wins\n",
    "4. If the documents DO NOT contain information to answer the question, respond with:\n",
    "   \"answer\": \"I don't have information about that in the company documents. I can only help with TechCorp policies, menus, and memos.\", \"cited_sources\": []\n",
    "5. DO NOT make up information or use knowledge outside the provided documents\n",
    "6. Be direct and concise\n",
    "\n",
    "Documents:\n",
    "{context}\n",
    "\n",
    "EMPLOYEE QUESTION: {question}\n",
    "\n",
    "ANSWER (with citations):\"\"\"\n",
    "        \n",
    "        print(\"Generating answer with Gemini...\\n\")\n",
    "        \n",
    "        # Use your existing Gemini client\n",
    "        response = self.client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            contents=prompt,\n",
    "            config={\n",
    "                \"response_mime_type\": \"application/json\",\n",
    "                \"response_json_schema\": PolicyAnswer.model_json_schema(),\n",
    "                \"temperature\": 0.5\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        return PolicyAnswer.model_validate_json(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7f152ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing RAG Pipeline...\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "rag = RagEngine(knowledge_base_path=\"knowledge_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1f9de805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Ingesting documents from: knowledge_base\n",
      "Found 3 files\n",
      "\n",
      "  üìÑ Processing: policy_v1_2021.txt\n",
      "      Type: DocType.POLICY\n",
      "      Date: 2021\n",
      "      Version: 1\n",
      "\n",
      "  üìÑ Processing: policy_v2_2024.txt\n",
      "      Type: DocType.POLICY\n",
      "      Date: 2024\n",
      "      Version: 2\n",
      "\n",
      "  üìÑ Processing: friday_cafeteria_menu.txt\n",
      "Warning: No date in friday_cafeteria_menu.txt, using file date: 2026-01-18\n",
      "      Type: DocType.MENU\n",
      "      Date: 2026\n",
      "      Version: 0\n",
      "\n",
      "üî® Creating vector store...\n",
      "‚úÖ Indexed 3 documents from 3 files\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag.ingest_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e13a1c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "QUERY: Can I work fully remotely this Friday?\n",
      "======================================================================\n",
      "\n",
      "üîç RETRIEVAL PHASE\n",
      "----------------------------------------------------------------------\n",
      "    Retrieved 3 documents\n",
      "    Query intent: DocType.POLICY\n",
      "\n",
      "  üìã Intent: policy\n",
      "  üìÑ Documents before filtering: 3\n",
      "  üìë Found 2 policy documents\n",
      "    üîç Multiple policies detected: 2\n",
      "      - policy_v2_2024.txt: year=2024, version=2\n",
      "      - policy_v1_2021.txt: year=2021, version=1\n",
      "    ‚úÖ Keeping latest: policy_v2_2024.txt (year: 2024, v2)\n",
      "  ‚úÖ Final documents: 1\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Generating answer with Gemini...\n",
      "\n",
      "\n",
      "‚úÖ Generated answer\n"
     ]
    }
   ],
   "source": [
    "answer = rag.query(\"Can I work fully remotely this Friday?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2f88a303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"You may be able to work remotely this Friday, as remote work is capped at 1 day per week. However, this must be approved by your manager, and you are expected to be in the office for the remaining 4 days of the week.\",\n",
      "  \"reasoning\": \"The TechCorp Return to Office Mandate (v2, 2024) clearly states that remote work is capped at 1 day per week and requires manager approval. Employees are expected to be in the office 4 days a week, and the 100% remote work policy was revoked.\",\n",
      "  \"cited_sources\": [\n",
      "    \"policy_v2_2024.txt\"\n",
      "  ],\n",
      "  \"policy_allows_remote\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(answer.model_dump_json(indent = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f349f1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "QUERY: Can I work fully remotely?\n",
      "======================================================================\n",
      "\n",
      "üîç RETRIEVAL PHASE\n",
      "----------------------------------------------------------------------\n",
      "    Retrieved 3 documents\n",
      "    Query intent: DocType.POLICY\n",
      "\n",
      "  üìã Intent: policy\n",
      "  üìÑ Documents before filtering: 3\n",
      "  üìë Found 2 policy documents\n",
      "    üîç Multiple policies detected: 2\n",
      "      - policy_v1_2021.txt: year=2021, version=1\n",
      "      - policy_v2_2024.txt: year=2024, version=2\n",
      "    ‚úÖ Keeping latest: policy_v2_2024.txt (year: 2024, v2)\n",
      "  ‚úÖ Final documents: 1\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Generating answer with Gemini...\n",
      "\n",
      "\n",
      "‚úÖ Generated answer\n"
     ]
    }
   ],
   "source": [
    "answer = rag.query(\"Can I work fully remotely?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "48f2ff4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"No, TechCorp's current policy does not allow for fully remote work. Remote work is capped at 1 day per week and must be approved by a manager. The 100% remote work policy from 2021 has been officially revoked.\",\n",
      "  \"reasoning\": \"The policy_v2_2024.txt document explicitly states that the 100% remote work policy from 2021 is revoked and that remote work is now capped at 1 day per week.\",\n",
      "  \"cited_sources\": [\n",
      "    \"policy_v2_2024.txt\"\n",
      "  ],\n",
      "  \"policy_allows_remote\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(answer.model_dump_json(indent = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7fb5a1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "QUERY: What is the menu for Friday?\n",
      "======================================================================\n",
      "\n",
      "üîç RETRIEVAL PHASE\n",
      "----------------------------------------------------------------------\n",
      "    Retrieved 3 documents\n",
      "    Query intent: DocType.MENU\n",
      "\n",
      "  üìã Intent: menu\n",
      "  üìÑ Documents before filtering: 3\n",
      "  ‚úÖ Keeping only MENU documents: 1\n",
      "  ‚úÖ Final documents: 1\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Generating answer with Gemini...\n",
      "\n",
      "\n",
      "‚úÖ Generated answer\n"
     ]
    }
   ],
   "source": [
    "answer = rag.query(\"What is the menu for Friday?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7eba99b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"The menu for Friday is Fish & Chips (Chef's Special!). Please note that the cafeteria is closed for cleaning on Friday afternoons.\",\n",
      "  \"reasoning\": \"The 'friday_cafeteria_menu.txt' document explicitly states the menu for Friday and a note about cafeteria closure.\",\n",
      "  \"cited_sources\": [\n",
      "    \"friday_cafeteria_menu.txt\"\n",
      "  ],\n",
      "  \"policy_allows_remote\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(answer.model_dump_json(indent = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c44b4f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "QUERY: What is happening in America Today?\n",
      "======================================================================\n",
      "\n",
      "üîç RETRIEVAL PHASE\n",
      "----------------------------------------------------------------------\n",
      "    Retrieved 3 documents\n",
      "    Query intent: DocType.GENERAL\n",
      "\n",
      "  üìã Intent: general\n",
      "  üìÑ Documents before filtering: 3\n",
      "  üîç General query - filtering all document types\n",
      "    üîç Multiple policies detected: 2\n",
      "      - policy_v1_2021.txt: year=2021, version=1\n",
      "      - policy_v2_2024.txt: year=2024, version=2\n",
      "    ‚úÖ Keeping latest: policy_v2_2024.txt (year: 2024, v2)\n",
      "  ‚úÖ Final documents: 2\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Generating answer with Gemini...\n",
      "\n",
      "\n",
      "‚úÖ Generated answer\n"
     ]
    }
   ],
   "source": [
    "answer = rag.query(\"What is happening in America Today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "00a56191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"I don't have information about that in the company documents. I can only help with TechCorp policies, menus, and memos.\",\n",
      "  \"reasoning\": \"The provided documents contain information about TechCorp's return to office policy and cafeteria menu, but no information regarding current events in America.\",\n",
      "  \"cited_sources\": [],\n",
      "  \"policy_allows_remote\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(answer.model_dump_json(indent = 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "policy-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
